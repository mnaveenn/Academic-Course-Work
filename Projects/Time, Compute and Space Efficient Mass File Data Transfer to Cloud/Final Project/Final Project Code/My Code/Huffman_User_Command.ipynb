{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the reusability of the same Huffman coding tree for compressing similar data files\n",
    "#### Naveen Narayanan Meyyappan and Praneeth Chandra Thota\n",
    "#### Date:11/27/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the reusability of the same Huffman coding tree for compressing similar data files\n",
      " \n",
      "Project By Naveen Narayanan Meyyappan and Praneeth Chandra Thota\n",
      " \n",
      "Working Directory:  C:\\Users\\USER\\huffman\n",
      " \n",
      "Enter the master text file for generating the encoding table: data.txt\n",
      "Encoding and Decoding tables generated\n",
      " \n",
      "Size of the encoding and decoding tables:  2635\n",
      "Enter the action to be performed (compress/decompress/exit): exit\n"
     ]
    }
   ],
   "source": [
    "# This file takes in commend from the user to perform Huffman encoding using the new approach\n",
    "# Importing Library Files\n",
    "import heapq\n",
    "import binascii\n",
    "import struct\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "# Defining the tree node in the heap structure\n",
    "class TreeNode:\n",
    "    def __init__(self, val=0, char=''):\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.val = val\n",
    "        self.char = char\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.val < other.val\n",
    "\n",
    "# Defining a function to compute the frequencies of each character\n",
    "def get_frequency(file):\n",
    "    frequency = {}\n",
    "    with open(file) as f:\n",
    "        while True:\n",
    "            c = f.read(1)\n",
    "            if not c:\n",
    "                break\n",
    "            frequency[c] = 1 if c not in frequency else frequency[c]+1\n",
    "    return frequency\n",
    "\n",
    "# This function is used to build the Huffman encoding tree using the concept of binary heaps\n",
    "def build_optimal_merge_tree(file):\n",
    "    frequencies = get_frequency(file)\n",
    "    heap = [TreeNode(frequencies[char], char) for char in frequencies]\n",
    "    heapq.heapify(heap)\n",
    "    while len(heap) > 1:\n",
    "        left, right = heapq.heappop(heap), heapq.heappop(heap)\n",
    "        parent = TreeNode(left.val+right.val)\n",
    "        parent.left = left\n",
    "        parent.right = right\n",
    "        heapq.heappush(heap, parent)\n",
    "    return heap[0]\n",
    "\n",
    "# In this function we use the developed tree and assigns 0s and 1s to get the codeword\n",
    "def build_encode_table(root):    \n",
    "    encode_table = {}\n",
    "    decode_table = {}\n",
    "    stack = [[\"\", root]]\n",
    "    while stack:\n",
    "        code, node = stack.pop(-1)\n",
    "        if node.left:\n",
    "            stack.append([code+'0', node.left])\n",
    "        if node.right:\n",
    "            stack.append([code+'1', node.right])\n",
    "        if not node.left and not node.right:\n",
    "            encode_table[node.char] = code\n",
    "            decode_table[code] = node.char\n",
    "    return encode_table, decode_table\n",
    "\n",
    "# This is the function that encodes the file and generates the file. It basically maps each character to its code word\n",
    "def encode_file(encode_table, input_file, output_file):    \n",
    "    try:\n",
    "        with open(input_file, \"r\") as input:\n",
    "            lines = input.read()\n",
    "            encoded_lines = '' \n",
    "            for c in lines:\n",
    "                encoded_lines += encode_table[c]\n",
    "            extra_padding = 8 - len(encoded_lines) % 8\n",
    "            encoded_lines += \"0\"*extra_padding\n",
    "            padded_info = \"{0:08b}\".format(extra_padding)\n",
    "            encoded_lines = padded_info + encoded_lines\n",
    "            byte_data = bytearray([int(encoded_lines[i:i+8], 2) for i in range(0, len(encoded_lines), 8)])\n",
    "            with open(output_file, \"wb\") as output:\n",
    "                output.write(bytes(byte_data))\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# We have a similar function to generate the decoding table\n",
    "def decode_file(decode_table, input_file, output_file):\n",
    "    try:\n",
    "        with open(input_file, 'rb') as input:\n",
    "            byte = input.read(1)\n",
    "            bit_data = ''\n",
    "            while byte:\n",
    "                bit_data += \"{0:08b}\".format(ord(byte.decode('ISO 8859-1')))\n",
    "                byte = input.read(1)\n",
    "            padding, bit_data = bit_data[:8], bit_data[8:]\n",
    "            padding = int(padding, 2)\n",
    "            bit_data = bit_data[:-padding]\n",
    "            with open(output_file, \"w\") as output:\n",
    "                code = ''\n",
    "                for bit in bit_data:\n",
    "                    code += bit\n",
    "                    if code in decode_table:\n",
    "                        output.write(decode_table[code])\n",
    "                        code = ''\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "# This is the function that compresses files based on the given encoding table\n",
    "def compress_file(input_file, output_file=\"\"):\n",
    "    encode_table = {}\n",
    "    if not output_file:\n",
    "        output_file = os.path.splitext(input_file)[0]+\"_compressed.bin\"\n",
    "    try:\n",
    "        with open('encoded.pkl', 'rb') as encoded_data:\n",
    "            encode_table = pkl.load(encoded_data)\n",
    "        return encode_file(encode_table, input_file, output_file)\n",
    "    except IOError:\n",
    "        print(\"File not found\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "# Decompressing function\n",
    "def decompress_file(input_file, output_file=\"\"):\n",
    "    decode_table = {}\n",
    "    if not output_file:\n",
    "        output_file = os.path.splitext(input_file)[0]+\"_decompressed.txt\"\n",
    "    try:\n",
    "        with open('decoded.pkl', 'rb') as decode_data:\n",
    "            decode_table = pkl.load(decode_data)\n",
    "        return decode_file(decode_table, input_file, output_file)\n",
    "    except IOError:\n",
    "        print(\"File not Found\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "# The user interface\n",
    "\n",
    "    print(\"Exploring the reusability of the same Huffman coding tree for compressing similar data files\")\n",
    "    print(\" \")\n",
    "    print(\"Project By Naveen Narayanan Meyyappan and Praneeth Chandra Thota\")\n",
    "    print (\" \")\n",
    "    print(\"Working Directory: \", os.getcwd())\n",
    "    print(\" \")\n",
    "    \n",
    "    action = \"\"\n",
    "    input_file = \"\"\n",
    "    while not input_file:\n",
    "            input_file = input(\"Enter the master text file for generating the encoding table: \").strip()\n",
    "            if input_file and os.path.splitext(input_file)[-1] != '.txt':\n",
    "                print(\"Please enter a valid file format!!\")\n",
    "                input_file = \"\"\n",
    "    root = build_optimal_merge_tree(input_file)\n",
    "    encode_table, decode_table = build_encode_table(root)            \n",
    "    output = open('encodingtable.pkl', 'wb')\n",
    "    pkl.dump(encode_table, output)\n",
    "    output.close()\n",
    "    output = open('decodingtable.pkl', 'wb')\n",
    "    pkl.dump(decode_table, output)\n",
    "    output.close()   \n",
    "    print(\"Encoding and Decoding tables generated\")\n",
    "    print(\" \")\n",
    "    statinfoenctable = os.stat('encodingtable.pkl')\n",
    "    print(\"Size of the encoding and decoding tables: \", statinfoenctable.st_size)\n",
    "    \n",
    "    while (1):\n",
    "        action = input(\"Enter the action to be performed (compress/decompress/exit): \").lower().strip()\n",
    "        input_file = \"\"\n",
    "        if action == \"compress\":\n",
    "            while not input_file:\n",
    "                input_file = input(\"Enter the text file to be compressed: \").strip()\n",
    "                if input_file and os.path.splitext(input_file)[-1] != '.txt':\n",
    "                    print(\"Please enter a valid file format!!\")\n",
    "                    input_file = \"\"\n",
    "            if compress_file(input_file):\n",
    "                print(input_file,\"Compression Successful\")\n",
    "            else:\n",
    "                print(input_file,\"Compression Failed\")\n",
    "        elif action == \"decompress\":\n",
    "            while not input_file:\n",
    "                input_file = input(\"Enter the text file to be decompressed: \").strip()\n",
    "                if input_file and os.path.splitext(input_file)[-1] != '.bin':\n",
    "                    print(\"Please enter a valid file format!!\")\n",
    "                    input_file = \"\"\n",
    "\n",
    "            if decompress_file(input_file):\n",
    "                print(input_file,\"Decompression Successful\")\n",
    "            else:\n",
    "                print(input_file,\"Decompression Failed\")\n",
    "        elif action==\"exit\":\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
