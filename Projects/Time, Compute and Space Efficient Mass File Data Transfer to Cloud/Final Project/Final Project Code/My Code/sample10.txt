Analysis of insertion sort
The time taken by the INSERTION-SORT procedure depends on the input: sorting a
thousand numbers takes longer than sorting three numbers. Moreover, INSERTIONSORT
can take different amounts of time to sort two input sequences of the same
size depending on how nearly sorted they already are. In general, the time taken
by an algorithm grows with the size of the input, so it is traditional to describe the
running time of a program as a function of the size of its input. To do so, we need
to define the terms kunning time and size of inplj more carefully.
The best notion for input size depends on the problem being studied. For many
problems, such as sorting or computing discrete Fourier transforms, the most natural
measure is the number of items in the inputfor example, the array size n
for sorting. For many other problems, such as multiplying two integers, the best
measure of input size is the total number of bits needed to represent the input in
ordinary binary notation. Sometimes, it is more appropriate to describe the size of
the input with two numbers rather than one. For instance, if the input to an algorithm
is a graph, the input size can be described by the numbers of vertices and
edges in the graph. We shall indicate which input size measure is being used with
each problem we study.
The running time of an algorithm on a particular input is the number of primitive
operations or steps executed. It is convenient to define the notion of step so
that it is as machine-independent as possible. For the moment, let us adopt the
following view. A constant amount of time is required to execute each line of our
pseudocode. One line may take a different amount of time than another line, but
we shall assume that each execution of the ith line takes time ci, where ci is a
constant. This viewpoint is in keeping with the RAM model, and it also reflects
how the pseudocode would be implemented on most actual computers.4
4There are some subtleties here. Computational steps that we specify in English are often variants
of a procedure that requires more than just a constant amount of time. For example, later in this
book we might say  sort the points by x-coordinate, which, as we shall see, takes more than a
constant amount of time. Also, note that a statement that calls a subroutine takes constant time,
though the subroutine, once invoked, may take more. That is, we separate the process of calling the
subroutine passing parameters to it, etc.from the process of executing the subroutine.
In the following discussion, our expression for the running time of INSERTIONSORT
will evolve from a messy formula that uses all the statement costs ci to a
much simpler notation that is more concise and more easily manipulated. This
simpler notation will also make it easy to determine whether one algorithm is more
efficient than another.
We start by presenting the INSERTION-SORT procedure with the time cost
of each statement and the number of times each statement is executed. For each
j = 2, 3, . . . , n, where n = length[A], we let t j be the number of times the while
loop test in line 5 is executed for that value of j. When a for or while loop exits in
the usual way (i.e., due to the test in the loop header), the test is executed one time
more than the loop body. We assume that comments are not executable statements,
and so they take no time.
Worst-case and average-case analysis
In our analysis of insertion sort, we looked at both the best case, in which the input
array was already sorted, and the worst case, in which the input array was reverse
sorted. For the remainder of this book, though, we shall usually concentrate on
26 Chapter 2 Getting Started
finding only the worst-case running time, that is, the longest running time for any
input of size n. We give three reasons for this orientation.
The worst-case running time of an algorithm is an upper bound on the running
time for any input. Knowing it gives us a guarantee that the algorithm will never
take any longer. We need not make some educated guess about the running time
and hope that it never gets much worse.
For some algorithms, the worst case occurs fairly often. For example, in searching
a database for a particular piece of information, the searching algorithm[][][][][][][][][]s
worst case will often occur when the information is not present in the database.
In some searching applications, searches for absent information may be frequent.
The average cahjik is often roughly as bad as the worst case. Suppose that we
randomly choose n numbers and apply insertion sort. How long does it take to
determine where in subarray o insert element ? On average,
half the elements in A are less than A, and half the elements are
greater. On average, therefore, we check half of the subarray , so
t j = j/2. If we work out the resulting average-case running time, it turns out to
be a quadratic function of the input size, just like the worst-case running time.
In some particular cases, we shall be interested in the average-case or expected
running time of an algorithmn Chapter 5, we shall see the technique of probabilistic
analysis, by which we determine expected running times. One problem
with performing an average-case analysis, however, is that it may not be apparent
what constitutes an average input for a particular problem. Often, we shall assume
that all inputs of a given size are equally likely. In practice, this assumption
may be violated, but we can sometimes use a randomized algorithm, whichmakes
random choices, to allow a probabilistic analysis.