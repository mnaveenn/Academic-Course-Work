{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the reusability of the same Huffman coding tree for compressing similar data files\n",
    "#### Naveen Narayanan Meyyappan and Praneeth Chandra Thota\n",
    "#### Date:11/27/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the reusability of the same Huffman coding tree for compressing similar data files\n",
      " \n",
      "Project By Naveen Narayanan Meyyappan and Praneeth Chandra Thota\n",
      " \n",
      "Working Directory:  C:\\Users\\USER\\huffman\n",
      " \n",
      "Let us perform the Huffman Coding on the file data.txt\n",
      " \n",
      "Step 1: Calculate the frequecies of each character in the file\n",
      " \n",
      "T : 5098\n",
      "h : 208917\n",
      "e : 854020\n",
      "  : 16907\n",
      "P : 6580\n",
      "r : 550333\n",
      "o : 559470\n",
      "j : 11586\n",
      "c : 327956\n",
      "t : 510271\n",
      "G : 3944\n",
      "u : 288722\n",
      "n : 561207\n",
      "b : 140498\n",
      "g : 184958\n",
      "E : 4035\n",
      "x : 22733\n",
      "f : 91546\n",
      "M : 7013\n",
      "y : 154027\n",
      "W : 2319\n",
      "d : 263585\n",
      "I : 2699\n",
      "a : 657510\n",
      "\n",
      " : 837993\n",
      "l : 441084\n",
      "w : 57675\n",
      "s : 549909\n",
      "i : 688121\n",
      "v : 74612\n",
      ", : 422\n",
      "k : 63264\n",
      "! : 36\n",
      "m : 225825\n",
      "p : 242427\n",
      ". : 2357\n",
      "D : 4490\n",
      "* : 48\n",
      "F : 3058\n",
      "V : 1636\n",
      "R : 3719\n",
      "B : 6092\n",
      "H : 4143\n",
      "C : 8456\n",
      ": : 36\n",
      "N : 3038\n",
      "S : 8586\n",
      "A : 8311\n",
      "q : 13678\n",
      "# : 10\n",
      "5 : 242\n",
      "6 : 231\n",
      "@ : 7\n",
      "U : 1272\n",
      "O : 2716\n",
      "; : 11\n",
      "/ : 79\n",
      "0 : 630\n",
      "9 : 261\n",
      "8 : 282\n",
      "7 : 177\n",
      "4 : 264\n",
      "3 : 310\n",
      "2 : 398\n",
      "1 : 400\n",
      "J : 1734\n",
      "z : 31776\n",
      "$ : 2\n",
      "+ : 2\n",
      "- : 47587\n",
      "% : 4\n",
      "' : 4461\n",
      "[ : 17\n",
      "= : 24\n",
      "] : 17\n",
      "L : 4373\n",
      "Y : 623\n",
      "< : 49\n",
      "> : 182\n",
      "X : 290\n",
      "? : 107\n",
      "( : 75\n",
      ") : 78\n",
      "\" : 499\n",
      "Q : 363\n",
      "K : 2744\n",
      "~ : 189\n",
      "_ : 2\n",
      "& : 9\n",
      "Z : 669\n",
      "| : 104\n",
      "\\ : 9\n",
      "^ : 1\n",
      "` : 1\n",
      "{ : 1\n",
      "} : 1\n",
      " \n",
      "Step 2: Generate the Encoding Table for the given data set(Data.txt)\n",
      " \n",
      "l : 11111\n",
      "h : 111101\n",
      "g : 111100\n",
      "i : 1110\n",
      "a : 1101\n",
      "f : 1100111\n",
      "B : 11001101111\n",
      "N : 110011011101\n",
      "K : 110011011100\n",
      "j : 1100110110\n",
      "x : 110011010\n",
      "O : 110011001111\n",
      "I : 110011001110\n",
      "T : 11001100110\n",
      "> : 1100110010111111\n",
      "7 : 1100110010111110\n",
      "3 : 110011001011110\n",
      "Z : 11001100101110\n",
      "U : 1100110010110\n",
      "0 : 11001100101011\n",
      "Y : 11001100101010\n",
      "/ : 11001100101001111\n",
      ") : 11001100101001110\n",
      "( : 11001100101001101\n",
      "! : 110011001010011001\n",
      "# : 11001100101001100011\n",
      "& : 11001100101001100010\n",
      "[ : 1100110010100110000\n",
      "X : 110011001010010\n",
      "8 : 110011001010001\n",
      "4 : 110011001010000\n",
      ". : 110011001001\n",
      "W : 110011001000\n",
      "D : 11001100011\n",
      "' : 11001100010\n",
      "S : 1100110000\n",
      "y : 110010\n",
      "c : 11000\n",
      "u : 10111\n",
      "b : 101101\n",
      "v : 1011001\n",
      "L : 10110001111\n",
      "H : 10110001110\n",
      "C : 1011000110\n",
      "  : 101100010\n",
      "z : 10110000\n",
      "n : 1010\n",
      "o : 1001\n",
      "r : 1000\n",
      "s : 0111\n",
      "t : 0110\n",
      "d : 01011\n",
      "p : 01010\n",
      "m : 01001\n",
      "k : 0100011\n",
      "w : 0100010\n",
      "A : 0100001111\n",
      "E : 01000011101\n",
      "G : 01000011100\n",
      "R : 01000011011\n",
      "9 : 010000110101111\n",
      "5 : 010000110101110\n",
      "\" : 01000011010110\n",
      "6 : 010000110101011\n",
      ": : 010000110101010111\n",
      "] : 0100001101010101101\n",
      "\\ : 01000011010101011001\n",
      "% : 010000110101010110001\n",
      "+ : 0100001101010101100001\n",
      "^ : 01000011010101011000001\n",
      "` : 01000011010101011000000\n",
      "< : 01000011010101010\n",
      "? : 0100001101010100\n",
      ", : 01000011010100\n",
      "J : 010000110100\n",
      "M : 0100001100\n",
      "q : 010000101\n",
      "P : 0100001001\n",
      "V : 010000100011\n",
      "1 : 01000010001011\n",
      "2 : 01000010001010\n",
      "| : 0100001000100111\n",
      "* : 01000010001001101\n",
      "= : 010000100010011001\n",
      "@ : 01000010001001100011\n",
      "{ : 01000010001001100010111\n",
      "} : 01000010001001100010110\n",
      "_ : 0100001000100110001010\n",
      "$ : 010000100010011000100\n",
      "; : 0100001000100110000\n",
      "~ : 010000100010010\n",
      "Q : 01000010001000\n",
      "F : 01000010000\n",
      "- : 0100000\n",
      "e : 001\n",
      "\n",
      " : 000\n",
      " \n",
      "Step 3: Save the encoded table as encoded.pkl for compression of other files\n",
      " \n",
      "Size of the encoding and decoding tables:  2635\n",
      " \n",
      "Step 4: Now let us use the above encoding table to compress and decompress the sample1.txt file using the encoding table from data.txt\n",
      " \n",
      "Compression Successful\n",
      "Compressed file saved as sample1_encoded.bin\n",
      "Size of the sample1.txt file is:  6898\n",
      "Size of the compressed file is:  4517\n",
      " \n",
      "Decompression Successful\n",
      "Decompressed file saved as sample_decoded1.txt\n",
      " \n",
      "Step 5: Let us continue the above steps for sample2.txt - sample10.txt \n",
      " \n",
      "Compression Successful\n",
      "Compressed file saved as sample2_encoded.bin\n",
      "Size of the sample2.txt file is:  3797\n",
      "Size of the compressed file is:  2509\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample3.txt file is:  4081\n",
      "Compressed file saved as sample3_encoded.bin\n",
      "Size of the compressed file is:  2762\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample4.txt file is:  4267\n",
      "Compressed file saved as sample4_encoded.bin\n",
      "Size of the compressed file is:  2988\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample5.txt file is:  4404\n",
      "Compressed file saved as sample5_encoded.bin\n",
      "Size of the compressed file is:  2976\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample6.txt file is:  3281\n",
      "Compressed file saved as sample6_encoded.bin\n",
      "Size of the compressed file is:  2231\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample7.txt file is:  3798\n",
      "Compressed file saved as sample7_encoded.bin\n",
      "Size of the compressed file is:  2773\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample8.txt file is:  4736\n",
      "Compressed file saved as sample8_encoded.bin\n",
      "Size of the compressed file is:  3228\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample9.txt file is:  5216\n",
      "Compressed file saved as sample9_encoded.bin\n",
      "Size of the compressed file is:  3511\n",
      " \n",
      "Compression Successful\n",
      "Size of the sample10.txt file is:  5665\n",
      "Compressed file saved as sample10_encoded.bin\n",
      "Size of the compressed file is:  3882\n",
      " \n",
      "Step 6: Now let us try to generate the compressed file of sample1.txt using the encoding table of sample1.txt\n",
      "Size of the compressed file using sample1.txt encoding table is 3720 \n",
      " \n",
      "From the above we see that the two compression ratios are:\n",
      "0.539 using the conventional method \n",
      "0.654 using the new method\n",
      "Eventhough the compression ratio is increased we have a faster compression algorithm\n",
      "The algorithm gets faster and faster compared to the original method only when the number of files to be compressed are more than 10(each with size more than 2000)\n",
      "On compressing all the 10 sample files we observe that the total size of compressed files including the header is 38627 bytes using the original Huffman compression algorithm and 34012 bytes using the new approach\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import binascii\n",
    "import struct\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, val=0, char=''):\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.val = val\n",
    "        self.char = char\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.val < other.val\n",
    "\n",
    "\n",
    "def get_frequency(file):\n",
    "    frequency = {}\n",
    "    with open(file) as f:\n",
    "        while True:\n",
    "            c = f.read(1)\n",
    "            if not c:\n",
    "                break\n",
    "            frequency[c] = 1 if c not in frequency else frequency[c]+1\n",
    "\n",
    "    return frequency\n",
    "\n",
    "\n",
    "def build_optimal_merge_tree(file):\n",
    "    frequencies = get_frequency(file)\n",
    "    print(\"Step 1: Calculate the frequecies of each character in the file\")\n",
    "    print(\" \")\n",
    "    for x in frequencies:\n",
    "        print(x,\":\",frequencies[x])\n",
    "    heap = [TreeNode(frequencies[char], char) for char in frequencies]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "\n",
    "        left, right = heapq.heappop(heap), heapq.heappop(heap)\n",
    "        parent = TreeNode(left.val+right.val)\n",
    "        parent.left = left\n",
    "        parent.right = right\n",
    "\n",
    "        heapq.heappush(heap, parent)\n",
    "        \n",
    "    return heap[0]\n",
    "\n",
    "\n",
    "\n",
    "def build_encode_table(root):\n",
    "    \n",
    "    encode_table = {}\n",
    "    decode_table = {}\n",
    "    stack = [[\"\", root]]\n",
    "    while stack:\n",
    "        code, node = stack.pop(-1)\n",
    "        if node.left:\n",
    "            stack.append([code+'0', node.left])\n",
    "        if node.right:\n",
    "            stack.append([code+'1', node.right])\n",
    "        if not node.left and not node.right:\n",
    "            encode_table[node.char] = code\n",
    "            decode_table[code] = node.char\n",
    "    \n",
    "    return encode_table, decode_table\n",
    "\n",
    "\n",
    "# Just work on this function....\n",
    "def encode_file(encode_table, input_file, output_file):\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, \"r\") as input:\n",
    "            lines = input.read()\n",
    "            encoded_lines = '' \n",
    "            for c in lines:\n",
    "                encoded_lines += encode_table[c]\n",
    "            extra_padding = 8 - len(encoded_lines) % 8\n",
    "            \n",
    "            encoded_lines += \"0\"*extra_padding\n",
    "            padded_info = \"{0:08b}\".format(extra_padding)\n",
    "            encoded_lines = padded_info + encoded_lines\n",
    "            byte_data = bytearray([int(encoded_lines[i:i+8], 2) for i in range(0, len(encoded_lines), 8)])\n",
    "            with open(output_file, \"wb\") as output:\n",
    "                output.write(bytes(byte_data))\n",
    "        return True\n",
    "\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def decode_file(decode_table, input_file, output_file):\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'rb') as input:\n",
    "            byte = input.read(1)\n",
    "            bit_data = ''\n",
    "            while byte:\n",
    "                bit_data += \"{0:08b}\".format(ord(byte.decode('ISO 8859-1')))\n",
    "                byte = input.read(1)\n",
    "            padding, bit_data = bit_data[:8], bit_data[8:]\n",
    "            padding = int(padding, 2)\n",
    "            bit_data = bit_data[:-padding]\n",
    "            with open(output_file, \"w\") as output:\n",
    "                code = ''\n",
    "                for bit in bit_data:\n",
    "                    code += bit\n",
    "                    if code in decode_table:\n",
    "                        output.write(decode_table[code])\n",
    "                        code = ''\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Exploring the reusability of the same Huffman coding tree for compressing similar data files\")\n",
    "    print(\" \")\n",
    "    print(\"Project By Naveen Narayanan Meyyappan and Praneeth Chandra Thota\")\n",
    "    print (\" \")\n",
    "    print(\"Working Directory: \", os.getcwd())\n",
    "    print(\" \")\n",
    "    print(\"Let us perform the Huffman Coding on the file data.txt\")\n",
    "    print(\" \")       \n",
    "    root = build_optimal_merge_tree(\"data.txt\")\n",
    "    encode_table, decode_table = build_encode_table(root)\n",
    "    print(\" \")\n",
    "    print(\"Step 2: Generate the Encoding Table for the given data set(Data.txt)\")\n",
    "    print(\" \")\n",
    "    for x in encode_table:\n",
    "        print(x,\":\",encode_table[x])\n",
    "    print(\" \")\n",
    "    print(\"Step 3: Save the encoded table as encoded.pkl for compression of other files\")\n",
    "    output = open('encodingtable.pkl', 'wb')\n",
    "    pkl.dump(encode_table, output)\n",
    "    output.close()\n",
    "    output = open('decodingtable.pkl', 'wb')\n",
    "    pkl.dump(decode_table, output)\n",
    "    output.close()\n",
    "    print(\" \")\n",
    "    statinfoenctable = os.stat('encodingtable.pkl')\n",
    "    print(\"Size of the encoding and decoding tables: \", statinfoenctable.st_size)\n",
    "    print(\" \")\n",
    "    print(\"Step 4: Now let us use the above encoding table to compress and decompress the sample1.txt file using the encoding table from data.txt\")\n",
    "    print(\" \")\n",
    "    if encode_file(encode_table,\"sample1.txt\",\"sample1_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        print(\"Compressed file saved as sample1_encoded.bin\")\n",
    "        statinfocomdata1org = os.stat('sample1.txt')\n",
    "        print(\"Size of the sample1.txt file is: \", statinfocomdata1org.st_size)\n",
    "        statinfocomdata1 = os.stat('sample1_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata1.st_size)\n",
    "        print(\" \")\n",
    "    else:\n",
    "        print(\"Compression Failed\")\n",
    "    if decode_file(decode_table,\"sample1_encoded.bin\",\"sample1_decoded.txt\"):\n",
    "        print(\"Decompression Successful\")\n",
    "        print(\"Decompressed file saved as sample_decoded1.txt\")\n",
    "        print(\" \")\n",
    "    else:\n",
    "        print(\"Decompression Failed\")\n",
    "    print(\"Step 5: Let us continue the above steps for sample2.txt - sample10.txt \")\n",
    "    print(\" \")\n",
    "    if encode_file(encode_table,\"sample2.txt\",\"sample2_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        print(\"Compressed file saved as sample2_encoded.bin\")\n",
    "        statinfocomdata2org = os.stat('sample2.txt')\n",
    "        print(\"Size of the sample2.txt file is: \", statinfocomdata2org.st_size)\n",
    "        statinfocomdata2 = os.stat('sample2_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata2.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample3.txt\",\"sample3_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata3org = os.stat('sample3.txt')\n",
    "        print(\"Size of the sample3.txt file is: \", statinfocomdata3org.st_size)\n",
    "        print(\"Compressed file saved as sample3_encoded.bin\")\n",
    "        statinfocomdata3 = os.stat('sample3_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata3.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample4.txt\",\"sample4_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata4org = os.stat('sample4.txt')\n",
    "        print(\"Size of the sample4.txt file is: \", statinfocomdata4org.st_size)\n",
    "        print(\"Compressed file saved as sample4_encoded.bin\")\n",
    "        statinfocomdata4 = os.stat('sample4_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata4.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample5.txt\",\"sample5_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata5org = os.stat('sample5.txt')\n",
    "        print(\"Size of the sample5.txt file is: \", statinfocomdata5org.st_size)\n",
    "        print(\"Compressed file saved as sample5_encoded.bin\")\n",
    "        statinfocomdata5 = os.stat('sample5_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata5.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample6.txt\",\"sample6_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata6org = os.stat('sample6.txt')\n",
    "        print(\"Size of the sample6.txt file is: \", statinfocomdata6org.st_size)\n",
    "        print(\"Compressed file saved as sample6_encoded.bin\")\n",
    "        statinfocomdata6 = os.stat('sample6_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata6.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample7.txt\",\"sample7_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata7org = os.stat('sample7.txt')\n",
    "        print(\"Size of the sample7.txt file is: \", statinfocomdata7org.st_size)\n",
    "        print(\"Compressed file saved as sample7_encoded.bin\")\n",
    "        statinfocomdata7 = os.stat('sample7_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata7.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample8.txt\",\"sample8_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata8org = os.stat('sample8.txt')\n",
    "        print(\"Size of the sample8.txt file is: \", statinfocomdata8org.st_size)\n",
    "        print(\"Compressed file saved as sample8_encoded.bin\")\n",
    "        statinfocomdata8 = os.stat('sample8_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata8.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample9.txt\",\"sample9_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata9org = os.stat('sample9.txt')\n",
    "        print(\"Size of the sample9.txt file is: \", statinfocomdata9org.st_size)\n",
    "        print(\"Compressed file saved as sample9_encoded.bin\")\n",
    "        statinfocomdata9 = os.stat('sample9_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata9.st_size)\n",
    "        print(\" \")\n",
    "    if encode_file(encode_table,\"sample10.txt\",\"sample10_encoded.bin\"):\n",
    "        print(\"Compression Successful\")\n",
    "        statinfocomdata10org = os.stat('sample10.txt')\n",
    "        print(\"Size of the sample10.txt file is: \", statinfocomdata10org.st_size)\n",
    "        print(\"Compressed file saved as sample10_encoded.bin\")\n",
    "        statinfocomdata10 = os.stat('sample10_encoded.bin')\n",
    "        print(\"Size of the compressed file is: \", statinfocomdata10.st_size)\n",
    "        print(\" \")\n",
    "    print(\"Step 6: Now let us try to generate the compressed file of sample1.txt using the encoding table of sample1.txt\")\n",
    "    print(\"Size of the compressed file using sample1.txt encoding table is 3720 \")\n",
    "    print(\" \")\n",
    "    print(\"From the above we see that the two compression ratios are:\")\n",
    "    print(\"0.539 using the conventional method \")\n",
    "    print(\"0.654 using the new method\")\n",
    "    print(\"Eventhough the compression ratio is increased we have a faster compression algorithm\")\n",
    "    print(\"The algorithm gets faster and faster compared to the original method only when the number of files to be compressed are more than 10(each with size more than 2000)\")\n",
    "    print(\"On compressing all the 10 sample files we observe that the total size of compressed files including the header is 38627 bytes using the original Huffman compression algorithm and 34012 bytes using the new approach\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
